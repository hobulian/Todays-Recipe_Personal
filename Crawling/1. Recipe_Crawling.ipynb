{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import matplotlib.font_manager as fm\n",
    "font_name = fm.FontProperties(fname=\"C:\\\\Windows\\\\Fonts\\\\malgun.ttf\").get_name()\n",
    "plt.rc(\"font\", family=font_name)\n",
    "\n",
    "import matplotlib as mlp\n",
    "mlp.rcParams[\"axes.unicode_minus\"] = False\n",
    "\n",
    "import urllib.request as req\n",
    "from urllib.request import urlopen\n",
    "from urllib.error import HTTPError, URLError\n",
    "import urllib.parse\n",
    "from bs4 import BeautifulSoup\n",
    "import bs4\n",
    "import requests\n",
    "\n",
    "import json\n",
    "import re\n",
    "from tqdm import notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# json 파일 생성\n",
    "data = {}\n",
    "data[\"data\"] = []\n",
    "\n",
    "with open('recipe_data.json', 'w', encoding=\"utf-8\") as make_file:    \n",
    "    json.dump(data, make_file, ensure_ascii=False, indent=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d63bf64574954dfab015ad1410b9bc2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3bd0e94a9d841728b3b52bb41672b5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ebdf0fe03a6f47e4a938d5775d15821f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb3a0e8cc78a4a329c5a13046629f3f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c777e0a50aa44b2f8c3d8ee9d7681f81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db1655b38ae64fc79899fe0cf09c02e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5582470c15b04cdb8417be60f70eb3e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbf12b5531fb4d17b8be7ff114263d53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "070cfe0df4b042d1979ff35bcfd9dca5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ac88ff8496a4db4ab06f51728b18455",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "716faf43e23c42d18763d3c63503c359",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3c14da22f1449dc835c0a294d7cb091",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63c09f4b5e594795a57489e27b0b186b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "faae8fbc07a64ec885aa03f3c44039f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\PythonWork\\Analysis\\Recipe_Crawling.ipynb Cell 3'\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/PythonWork/Analysis/Recipe_Crawling.ipynb#ch0000002?line=115'>116</a>\u001b[0m url \u001b[39m=\u001b[39m urllib\u001b[39m.\u001b[39mparse\u001b[39m.\u001b[39murljoin(base, i)\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/PythonWork/Analysis/Recipe_Crawling.ipynb#ch0000002?line=117'>118</a>\u001b[0m header \u001b[39m=\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39mUser-Agent\u001b[39m\u001b[39m\"\u001b[39m : \u001b[39m\"\u001b[39m\u001b[39mMozilla/5.0\u001b[39m\u001b[39m\"\u001b[39m}\n\u001b[1;32m--> <a href='vscode-notebook-cell:/c%3A/PythonWork/Analysis/Recipe_Crawling.ipynb#ch0000002?line=118'>119</a>\u001b[0m page \u001b[39m=\u001b[39m requests\u001b[39m.\u001b[39;49mget(url, headers\u001b[39m=\u001b[39;49mheader)\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/PythonWork/Analysis/Recipe_Crawling.ipynb#ch0000002?line=119'>120</a>\u001b[0m page\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/PythonWork/Analysis/Recipe_Crawling.ipynb#ch0000002?line=120'>121</a>\u001b[0m \u001b[39m# 가져온 웹 소스를 트리 구조로 변환\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\dbs03\\anaconda3\\lib\\site-packages\\requests\\api.py:75\u001b[0m, in \u001b[0;36mget\u001b[1;34m(url, params, **kwargs)\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget\u001b[39m(url, params\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m     65\u001b[0m     \u001b[39mr\u001b[39m\u001b[39m\"\"\"Sends a GET request.\u001b[39;00m\n\u001b[0;32m     66\u001b[0m \n\u001b[0;32m     67\u001b[0m \u001b[39m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[39m    :rtype: requests.Response\u001b[39;00m\n\u001b[0;32m     73\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 75\u001b[0m     \u001b[39mreturn\u001b[39;00m request(\u001b[39m'\u001b[39m\u001b[39mget\u001b[39m\u001b[39m'\u001b[39m, url, params\u001b[39m=\u001b[39mparams, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\dbs03\\anaconda3\\lib\\site-packages\\requests\\api.py:61\u001b[0m, in \u001b[0;36mrequest\u001b[1;34m(method, url, **kwargs)\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[39m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[0;32m     58\u001b[0m \u001b[39m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[0;32m     59\u001b[0m \u001b[39m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[0;32m     60\u001b[0m \u001b[39mwith\u001b[39;00m sessions\u001b[39m.\u001b[39mSession() \u001b[39mas\u001b[39;00m session:\n\u001b[1;32m---> 61\u001b[0m     \u001b[39mreturn\u001b[39;00m session\u001b[39m.\u001b[39mrequest(method\u001b[39m=\u001b[39mmethod, url\u001b[39m=\u001b[39murl, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\dbs03\\anaconda3\\lib\\site-packages\\requests\\sessions.py:529\u001b[0m, in \u001b[0;36mSession.request\u001b[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[0;32m    524\u001b[0m send_kwargs \u001b[39m=\u001b[39m {\n\u001b[0;32m    525\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mtimeout\u001b[39m\u001b[39m'\u001b[39m: timeout,\n\u001b[0;32m    526\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mallow_redirects\u001b[39m\u001b[39m'\u001b[39m: allow_redirects,\n\u001b[0;32m    527\u001b[0m }\n\u001b[0;32m    528\u001b[0m send_kwargs\u001b[39m.\u001b[39mupdate(settings)\n\u001b[1;32m--> 529\u001b[0m resp \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msend(prep, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39msend_kwargs)\n\u001b[0;32m    531\u001b[0m \u001b[39mreturn\u001b[39;00m resp\n",
      "File \u001b[1;32mc:\\Users\\dbs03\\anaconda3\\lib\\site-packages\\requests\\sessions.py:687\u001b[0m, in \u001b[0;36mSession.send\u001b[1;34m(self, request, **kwargs)\u001b[0m\n\u001b[0;32m    684\u001b[0m         \u001b[39mpass\u001b[39;00m\n\u001b[0;32m    686\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m stream:\n\u001b[1;32m--> 687\u001b[0m     r\u001b[39m.\u001b[39;49mcontent\n\u001b[0;32m    689\u001b[0m \u001b[39mreturn\u001b[39;00m r\n",
      "File \u001b[1;32mc:\\Users\\dbs03\\anaconda3\\lib\\site-packages\\requests\\models.py:838\u001b[0m, in \u001b[0;36mResponse.content\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    836\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_content \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    837\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 838\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_content \u001b[39m=\u001b[39m \u001b[39mb\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m.\u001b[39;49mjoin(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49miter_content(CONTENT_CHUNK_SIZE)) \u001b[39mor\u001b[39;00m \u001b[39mb\u001b[39m\u001b[39m'\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    840\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_content_consumed \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    841\u001b[0m \u001b[39m# don't need to release the connection; that's been handled by urllib3\u001b[39;00m\n\u001b[0;32m    842\u001b[0m \u001b[39m# since we exhausted the data.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\dbs03\\anaconda3\\lib\\site-packages\\requests\\models.py:760\u001b[0m, in \u001b[0;36mResponse.iter_content.<locals>.generate\u001b[1;34m()\u001b[0m\n\u001b[0;32m    758\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mraw, \u001b[39m'\u001b[39m\u001b[39mstream\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[0;32m    759\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 760\u001b[0m         \u001b[39mfor\u001b[39;00m chunk \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mraw\u001b[39m.\u001b[39mstream(chunk_size, decode_content\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m):\n\u001b[0;32m    761\u001b[0m             \u001b[39myield\u001b[39;00m chunk\n\u001b[0;32m    762\u001b[0m     \u001b[39mexcept\u001b[39;00m ProtocolError \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[1;32mc:\\Users\\dbs03\\anaconda3\\lib\\site-packages\\urllib3\\response.py:575\u001b[0m, in \u001b[0;36mHTTPResponse.stream\u001b[1;34m(self, amt, decode_content)\u001b[0m\n\u001b[0;32m    559\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    560\u001b[0m \u001b[39mA generator wrapper for the read() method. A call will block until\u001b[39;00m\n\u001b[0;32m    561\u001b[0m \u001b[39m``amt`` bytes have been read from the connection or until the\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    572\u001b[0m \u001b[39m    'content-encoding' header.\u001b[39;00m\n\u001b[0;32m    573\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    574\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchunked \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msupports_chunked_reads():\n\u001b[1;32m--> 575\u001b[0m     \u001b[39mfor\u001b[39;00m line \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mread_chunked(amt, decode_content\u001b[39m=\u001b[39mdecode_content):\n\u001b[0;32m    576\u001b[0m         \u001b[39myield\u001b[39;00m line\n\u001b[0;32m    577\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\dbs03\\anaconda3\\lib\\site-packages\\urllib3\\response.py:767\u001b[0m, in \u001b[0;36mHTTPResponse.read_chunked\u001b[1;34m(self, amt, decode_content)\u001b[0m\n\u001b[0;32m    764\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[0;32m    766\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m--> 767\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_update_chunk_length()\n\u001b[0;32m    768\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchunk_left \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m    769\u001b[0m         \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\dbs03\\anaconda3\\lib\\site-packages\\urllib3\\response.py:697\u001b[0m, in \u001b[0;36mHTTPResponse._update_chunk_length\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    695\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchunk_left \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    696\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[1;32m--> 697\u001b[0m line \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fp\u001b[39m.\u001b[39;49mfp\u001b[39m.\u001b[39;49mreadline()\n\u001b[0;32m    698\u001b[0m line \u001b[39m=\u001b[39m line\u001b[39m.\u001b[39msplit(\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m;\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m1\u001b[39m)[\u001b[39m0\u001b[39m]\n\u001b[0;32m    699\u001b[0m \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\dbs03\\anaconda3\\lib\\socket.py:704\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    702\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m    703\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 704\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sock\u001b[39m.\u001b[39;49mrecv_into(b)\n\u001b[0;32m    705\u001b[0m     \u001b[39mexcept\u001b[39;00m timeout:\n\u001b[0;32m    706\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_timeout_occurred \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\dbs03\\anaconda3\\lib\\ssl.py:1241\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[1;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[0;32m   1237\u001b[0m     \u001b[39mif\u001b[39;00m flags \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m   1238\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m   1239\u001b[0m           \u001b[39m\"\u001b[39m\u001b[39mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m\n\u001b[0;32m   1240\u001b[0m           \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m)\n\u001b[1;32m-> 1241\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mread(nbytes, buffer)\n\u001b[0;32m   1242\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1243\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[1;32mc:\\Users\\dbs03\\anaconda3\\lib\\ssl.py:1099\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[1;34m(self, len, buffer)\u001b[0m\n\u001b[0;32m   1097\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1098\u001b[0m     \u001b[39mif\u001b[39;00m buffer \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m-> 1099\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sslobj\u001b[39m.\u001b[39;49mread(\u001b[39mlen\u001b[39;49m, buffer)\n\u001b[0;32m   1100\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1101\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sslobj\u001b[39m.\u001b[39mread(\u001b[39mlen\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "header = {\"User-Agent\" : \"Mozilla/5.0\"}\n",
    "\n",
    "# 해당 사이트에 총 25개의 카테고리가 있음을 확인(1 ~ 25)\n",
    "for i in notebook.tqdm(range(25)): # 0 ~ 24\n",
    "    theme_url = \"https://2bob.co.kr/recipe.php?id=list&fKeyList=&fKeyValue=&eTheme={}\"\n",
    "    theme_url = theme_url.format(i+1)\n",
    "\n",
    "\n",
    "    # 한개의카테고리에 몇개의 큰 페이지(5개 묶음 ex> 1 ~ 5, 6 ~ 10, 11 ~ 12)가 있는지 파악\n",
    "    # ex) 3페이지일 경우 리스트가 [1, 6, 11]\n",
    "    # ex) 2페이지일 경우 리스트가 [1. 6]\n",
    "    next_page_num_list = [1]\n",
    "    k = 0\n",
    "    while(True):\n",
    "        # 웹 소스 준비\n",
    "        url = theme_url + \"&OrderCondition=&OrderBy=&page={}\"      \n",
    "        url = url.format(next_page_num_list[k])\n",
    "        page = requests.get(url, headers=header)\n",
    "\n",
    "        soup = BeautifulSoup(page.text, \"html.parser\")\n",
    "\n",
    "        if(soup.find(\"img\", alt=\"마지막으로\") != None):    \n",
    "            # 페이지에서 >> 버튼(\"마지막으로\")이 있을경우 다음 큰 페이지가 있음을 의미함\n",
    "            next_Page = soup.find(\"img\", alt=\"마지막으로\").parent\n",
    "        else:\n",
    "            break   # 마지막으로 버튼이 없을 경우 해당 카테고리의 마지막 큰 페이지이므로 반복문 종료\n",
    "        if(next_page_num_list[k] < int(next_Page[\"href\"].split(\"=\")[-1])):\n",
    "            next_page_num_list.append(int(next_Page[\"href\"].split(\"=\")[-1]))\n",
    "            k = k + 1\n",
    "#             print(next_Page[\"href\"].split(\"=\")[-1])\n",
    "        else:\n",
    "            break\n",
    "\n",
    "#     print(next_page_num_list)\n",
    "\n",
    "    for lead_page_num in notebook.tqdm(next_page_num_list):\n",
    "\n",
    "        # 웹 소스 준비\n",
    "        url = theme_url + \"&OrderCondition=&OrderBy=&page={}\"     \n",
    "        url = url.format(lead_page_num)\n",
    "\n",
    "        \n",
    "        page = requests.get(url, headers=header)\n",
    "\n",
    "        # 가져온 웹 소스를 트리 구조로 변환\n",
    "        soup = BeautifulSoup(page.text, \"html.parser\")\n",
    "\n",
    "        # urljoin을 위한 base 선언\n",
    "        base = \"https://2bob.co.kr\"\n",
    "        base2 = \"https://2bob.co.kr/recipe.php\"\n",
    "\n",
    "        # 한개의 카테고리의 페이지 url 가져오기\n",
    "        page_list = []\n",
    "        page_list.append(url)\n",
    "\n",
    "        if(soup.find(\"p\", \"paging_num\") != None):\n",
    "            if(soup.find(\"p\", \"paging_num\").a != None):\n",
    "                page_list.append(soup.find(\"p\", \"paging_num\").a[\"href\"])\n",
    "                next_pages = soup.find(\"p\", \"paging_num\").a.next_siblings\n",
    "\n",
    "                for page in next_pages:\n",
    "                    page_list.append(page[\"href\"])\n",
    "\n",
    "        for page in notebook.tqdm(page_list):\n",
    "            if(page == url):\n",
    "                url = page\n",
    "            else:\n",
    "                url = base2 + page\n",
    "\n",
    "            page = requests.get(url, headers=header)\n",
    "\n",
    "            # 가져온 웹 소스를 트리 구조로 변환\n",
    "            soup = BeautifulSoup(page.text, \"html.parser\")\n",
    "\n",
    "            # 페이지당 4줄, 4줄의 맨 앞에있는 레시피만 ml_none 클래스 부여되어있음\n",
    "            # 따라서 뒤에 따라오는 4개의 레시피는 해당 레시피 기준 siblings을 사용하여 가져옴\n",
    "\n",
    "            # 가로기준 맨 앞 항목의 링크 가져오기\n",
    "            urls = soup.select('li.ml_none > a')\n",
    "            lead_urls_list = []\n",
    "            for url in urls:\n",
    "                lead_urls_list.append(url[\"href\"])\n",
    "\n",
    "            # 맨 앞 항목의 링크를 기준으로 따라오는 4개의 링크 가져오기\n",
    "            follow_url_list=[]\n",
    "            for lead_url in lead_urls_list:\n",
    "                urls = soup.find(\"a\", href=lead_url).parent.next_siblings\n",
    "                for url in urls:\n",
    "                    if(type(url) == bs4.element.Tag):\n",
    "                        follow_url_list.append(list(url.children)[1][\"href\"])\n",
    "\n",
    "            # 두개의 리스트 합치기\n",
    "            url_list = lead_urls_list + follow_url_list\n",
    "\n",
    "            # 합쳐진 리스트의 중복 제거\n",
    "            url_list = set(url_list)\n",
    "            url_list = list(url_list)\n",
    "\n",
    "            # 괄호, \\r\\n 제거를 위한 패턴 생성\n",
    "            pattern1 = r'\\([^)]*\\)'\n",
    "            pattern2 = '\\r\\n'\n",
    "            pattern3 = '\\n'\n",
    "\n",
    "            # 생성해 놓은 json파일 load\n",
    "            with open('recipe_data.json', \"r\", encoding='utf-8') as json_file:    \n",
    "                json_data = json.load(json_file)\n",
    "\n",
    "                    \n",
    "            if(len(json_data[\"data\"]) == 0): # 처음 저장할 경우\n",
    "                cnt = 0\n",
    "            else: # 기존에 테이터가 있을 경우\n",
    "                cnt = json_data[\"data\"][-1][\"code\"] + 1   \n",
    "\n",
    "            for i in notebook.tqdm(url_list):\n",
    "                # 웹 소스 준비\n",
    "                url = urllib.parse.urljoin(base, i)\n",
    "\n",
    "                header = {\"User-Agent\" : \"Mozilla/5.0\"}\n",
    "                page = requests.get(url, headers=header)\n",
    "                page\n",
    "                # 가져온 웹 소스를 트리 구조로 변환\n",
    "                soup = BeautifulSoup(page.text, \"html.parser\")\n",
    "\n",
    "                # 레시피 명\n",
    "                title = soup.find('h2', class_=\"prod_title\").get_text()\n",
    "#                 print(title)\n",
    "\n",
    "                # 필수재료\n",
    "                ingredients = soup.find('p', class_=\"mate_list\").get_text()\n",
    "\n",
    "                # 재료명에서 괄호와 괄호안의 정보 삭제\n",
    "                ingredients = re.sub(pattern=pattern1, repl='', string=ingredients)\n",
    "\n",
    "                # 재료명에서 \\r\\n 제거\n",
    "                ingredients = re.sub(pattern=pattern2, repl='', string=ingredients)\n",
    "                \n",
    "                # 재료명에서 \\n 제거\n",
    "                ingredients = re.sub(pattern=pattern3, repl='', string=ingredients)\n",
    "\n",
    "                # 리스트로 변환\n",
    "                temp_list = ingredients.split(',')\n",
    "\n",
    "                ingredients_list = []\n",
    "                # 공백 제거\n",
    "                for i in temp_list:\n",
    "                    i = re.sub(\" \", \"\", string=i)\n",
    "                    ingredients_list.append(i)\n",
    "\n",
    "#                 print(ingredients_list)\n",
    "\n",
    "\n",
    "                # 필수재료 이외의 재료와 양념이 있다면 가져오기\n",
    "                if(soup.find('p', class_=\"mate_list\").parent.next_siblings != None):\n",
    "                    siblings = soup.find('p', class_=\"mate_list\").parent.next_siblings\n",
    "                    for sibling in siblings:\n",
    "                        if(type(sibling) == bs4.element.Tag):\n",
    "\n",
    "                            if(sibling.p != None):\n",
    "\n",
    "                                ingredients = sibling.p.get_text()\n",
    "\n",
    "                                # 재료명에서 괄호와 괄호안의 정보 삭제\n",
    "                                ingredients = re.sub(pattern=pattern1, repl='', string=ingredients)\n",
    "\n",
    "                                # 재료명에서 \\r\\n 제거\n",
    "                                ingredients = re.sub(pattern=pattern2, repl='', string=ingredients)\n",
    "\n",
    "                                # 재료명에서 \\n 제거\n",
    "                                ingredients = re.sub(pattern=pattern3, repl='', string=ingredients)\n",
    "\n",
    "                                # 리스트로 변환\n",
    "                                temp_list = ingredients.split(',')\n",
    "\n",
    "\n",
    "                                # 공백 제거\n",
    "                                for i in temp_list:\n",
    "                                    i = re.sub(\" \", \"\", string=i)\n",
    "                                    ingredients_list.append(i)\n",
    "                \n",
    "                # 특수 양념 예외처리\n",
    "                for ingredient in ingredients_list:\n",
    "                    if(\"+\" in ingredient):\n",
    "                        temp = ingredient.split(\"+\")\n",
    "                        ingredients_list.remove(ingredient)\n",
    "                        ingredients_list = ingredients_list + temp\n",
    "    \n",
    "                json_data['data'].append({\n",
    "                    \"code\" : cnt,\n",
    "                    \"title\" : title,\n",
    "                    \"ingredients\" : ingredients_list,\n",
    "                    \"url\" : url\n",
    "                })\n",
    "#                 print(\"--------------------------------------------------\")\n",
    "                cnt = cnt + 1\n",
    "                # json 파일 저장\n",
    "                with open('recipe_data.json', \"w\", encoding='utf-8') as outfile:      ####################################### 수정해야할 곳 ####################\n",
    "                    json.dump(json_data, outfile, indent=\"\\t\", ensure_ascii=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "3abef859d002c6750ca6e31532104864d50c2c03ecac513d70642831473e898a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
